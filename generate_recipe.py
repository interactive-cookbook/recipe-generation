import networkx as nx
import json
import penman
from pathlib import Path
import argparse
from typing import Tuple, List

from graph_processing.action_amr_graph_mappings import add_semantic_representations
from model.inference import RecipeGenerator
from amr_processing.penman_networkx_conversions import networkx2penman
from graph_processing.recipe_graph import read_graph_from_conllu
from graph_processing.graph_traversal import order_actions_pf, order_actions_pf_lf, order_actions_token_ids, \
    order_actions_topological, order_actions_pf_lf_id

"""
Functions to generate a recipe by traversing an action graph and generating a sentence
for each action node from its amr graph and the previous sentence
"""


def prepare_input_amr_str(amr_graph: nx.DiGraph) -> str:
    """
    convert amr_graph into its string representation without metadata, i.e. the input format required by the
    generation model (does not remove token alignments!)
    :param amr_graph: networkX graph of the AMR
    :return: linearized penman format of the AMR without the metadata
    """
    # convert to string in penman format without indentation, without line breaks and without metadata
    penman_amr = networkx2penman(amr_graph)
    penman_str = penman.encode(penman_amr, indent=0)

    penman_lines = penman_str.split('\n')
    cleaned_lines = [l for l in penman_lines if not l.startswith('# ::')]
    amr_graph_str = ' '.join(cleaned_lines)
    return amr_graph_str


def generate(amr_graph: nx.DiGraph, context: str, generator: RecipeGenerator) -> List[str]:
    """
    Generates a sentence for an amr graph based on context
    :param amr_graph: an AMR graph as networkx graph
    :param context: list with the previously generated sentences or empty list if no context
    :param generator: an instantiated RecipeGenerator object
    :return: a list with the sentence generated by RecipeGenerator.model from the amr and the context
    """
    # get input string format for amr graph
    amr_graph_str = prepare_input_amr_str(amr_graph)

    # generate function expects a list of contexts and list of amr graphs for handling batches
    model_output, clip = generator.generate([context], [amr_graph_str])

    if clip[0]:
        print(f'Warning: input length exceeded the max_in_len specified and input got truncated. Please increase'
              f'max_in_len or use shorter inputs')

    return model_output


def generate_recipe_ac_graph(action_graph: nx.DiGraph,
                             generation_config,
                             ordering: str = "df-lf-id",
                             context_len: int = 1) -> Tuple[List, List]:
    """
    Generates a recipe for an action graph instruction by instruction
    :param action_graph: an action graph (networkx object)
    :param generation_config: a .json file with the configuration parameters for the generation model to use
    :param ordering: the ordering function to use, can be "top", "ids", "df", "df-lf" and "df-lf-id"
    :param context_len: the context length, i.e. how many previous sentences to consider
    :return: the (ordered) list of the generated sentences
             the (ordered) list of the action nodes for which sentences were generated; if an AMR contains
                    several action nodes then only the first encountered action node is part of the list, i.e.
                    there is one action node per generated sentence
    """
    generated_sentences = []        # list for storing the generated instructions

    # keep track of action-events for which an instruction is already created
    realized_actions = []
    amrid2realizedaction = dict()
    already_realized_amrs = []

    # load the model and instantiate inference class object
    print("---------- Loading Recipe Generator ----------")
    with open(generation_config, 'r', encoding='utf-8') as c:
        configuration_dict = json.load(c)
    generator = RecipeGenerator(configuration_dict)

    # add the corresponding amr graphs
    print("---------- Loading Semantic Representations ----------")
    sem_action_graph = add_semantic_representations(action_graph)

    # create an order of the action graphs
    if ordering == "top":
        action_ordering = order_actions_topological(sem_action_graph)
    elif ordering == "ids":
        action_ordering = order_actions_token_ids(sem_action_graph)
    elif ordering == "pf":
        action_ordering = order_actions_pf(sem_action_graph)
    elif ordering == "pf-lf":
        action_ordering = order_actions_pf_lf(sem_action_graph)
    elif ordering == "pf-lf-id":
        action_ordering = order_actions_pf_lf_id(sem_action_graph)
    else:
        raise ValueError('Ordering values can only be "top", "ids", "pf", "pf-lf" or "pf-lf-id"')

    # loop through the ordered action nodes
    print("---------- Starting Generation ----------")

    for action_node in action_ordering:
        # get semantic representation of action node
        sem_repr = nx.get_node_attributes(sem_action_graph, 'amr')[action_node]
        # skip unaligned action nodes
        if not sem_repr:
            continue
        amr_id = sem_repr.graph['id']
        # skip already covered amr graphs
        if amr_id in already_realized_amrs:
            amrid2realizedaction[amr_id].append(action_node)
            continue

        # select context sentences
        if context_len == 0:
            context_sentences = []
        else:
            context_sentences = generated_sentences[-context_len:]
        context = ' '.join(context_sentences)

        # run generation
        gen_snt = generate(sem_repr, context, generator)

        generated_sentences.extend(gen_snt)
        realized_actions.append(action_node)
        already_realized_amrs.append(amr_id)
        amrid2realizedaction[amr_id] = [action_node]

    print("---------- Finished Generation ----------")

    # Reconstruct the ordered list of the actions for which an instruction was generated
    ordered_actions = []
    for amr_id in already_realized_amrs:
        ordered_actions.append(amrid2realizedaction[amr_id])
    assert realized_actions == [l[0] for l in amrid2realizedaction.values()]

    return generated_sentences, ordered_actions


def generate_recipe_one_ordering(ac_graph: nx.DiGraph, configuration_file: Path, ordering: str,
                             context_len: int, output_file):
    """

    :param ac_graph: an action graph (networkx object)
    :param configuration_file: a .json file with the configuration parameters for the generation model to use
    :param ordering: name of the traversal / ordering function to use
    :param context_len: the context length, i.e. how many previous sentences to consider
    :param output_file: path to file where results get saved
    :return:
    """
    recipe, action_order = generate_recipe_ac_graph(action_graph=ac_graph,
                                                    generation_config=configuration_file,
                                                    ordering=ordering,
                                                    context_len=context_len)
    with open(output_file, 'w', encoding='utf-8') as out:
        for sent in recipe:
            out.write(f'{sent}\n')


def generate_recipe_different_orderings(ac_graph: nx.DiGraph, configuration_file: Path, ordering_list: list,
                                 ordering_names: dict, context_len: int, output_file):
    """
    Generates a recipe for an action graph using all graph traversals specified in ordering_list and saves the text to
    a file with one column (tab separated) per ordering, one sentence per line
    or prints the generated recipes if not output file is specified
    :param ac_graph: an action graph (networkx object)
    :param configuration_file: a .json file with the configuration parameters for the generation model to use
    :param ordering_list: list with the names of the traversal / ordering functions to use
    :param ordering_names: dictionary with names of the traversal functions to write into the result file
    :param context_len: the context length, i.e. how many previous sentences to consider
    :param output_file: path to file where results get saved or None if results should only get printed out
    :return:
    """
    max_recipe_len = 0
    recipes = dict()
    action_ordering = dict()
    for ord in ordering_list:
        recipe, action_order = generate_recipe_ac_graph(action_graph=ac_graph,
                                                        generation_config=configuration_file,
                                                        ordering=ord,
                                                        context_len=context_len)
        max_recipe_len = len(recipe) if len(recipe) > max_recipe_len else max_recipe_len
        recipes[ord] = recipe
        action_ordering[ord] = action_order

    # write to output file
    if output_file:
        rows = [[] for m in range(max_recipe_len)]
        with open(output_file, 'w', encoding='utf-8') as out:
            header = []
            for ord in ordering_list:
                header.append(ordering_names[ord])
                recipe_sents = recipes[ord]
                for ind, sent in enumerate(recipe_sents):
                    rows[ind].append(sent)

            header_line = '\t'.join(header)
            out.write(f'{header_line}\n')
            for row in rows:
                line = '\t'.join(row)
                out.write(f'{line}\n')
    # or print to command line
    else:
        for ord in ordering_list:
            print(f'{ordering_names[ord]}:')
            for sent in recipes[ord]:
                print(sent)
            print('\n')

    return recipes, action_ordering


if __name__=='__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('--file', required=True)
    parser.add_argument('--cont', required=True)
    parser.add_argument('--order', required=False)
    parser.add_argument('--config', required=True)
    parser.add_argument('--out', required=False)
    args = parser.parse_args()

    ac_graph_file = args.file
    ac_graph = read_graph_from_conllu(Path(ac_graph_file))
    context_len = int(args.cont)
    out_file = args.out if args.out else None
    configuration_file = args.config

    # needed for the headers if a csv file with recipes for different traversals gets created
    ordering_names = {'top': 'NetworkX Topological Order', 'ids': 'Token ID Ordering', 'pf': 'Path-First Ordering',
                      'pf-lf': 'Path-First Longest-First Ordering', 'pf-lf-id': 'Path-First Longest-First IDs Ordering'}

    ordering = args.order if args.order else 'pf-lf-id'
    possible_orderings = ['top', 'ids', 'pf', 'pf-lf', 'pf-lf-id']

    if ordering == 'all':
        generate_recipe_different_orderings(ac_graph=ac_graph,
                                            configuration_file=configuration_file,
                                            ordering_list=possible_orderings,
                                            ordering_names=ordering_names,
                                            context_len=context_len,
                                            output_file=out_file)
    else:
        assert ordering in possible_orderings
        generate_recipe_one_ordering(ac_graph=ac_graph,
                                     configuration_file=configuration_file,
                                     ordering=ordering,
                                     context_len=context_len,
                                     output_file=out_file)




